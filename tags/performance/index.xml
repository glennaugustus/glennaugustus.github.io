<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Performance on glennaugustus.com</title><link>https://glennaugustus.com/tags/performance/</link><description>Recent content in Performance on glennaugustus.com</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 19 Aug 2015 13:27:52 +0000</lastBuildDate><atom:link href="https://glennaugustus.com/tags/performance/index.xml" rel="self" type="application/rss+xml"/><item><title>Compute Workload Abstraction - Part 5 or When Milli and Micro Meet</title><link>https://glennaugustus.com/post/compute-workload-abstraction-part-5-or-when-milli-and-micro-meet/</link><pubDate>Wed, 19 Aug 2015 13:27:52 +0000</pubDate><guid>https://glennaugustus.com/post/compute-workload-abstraction-part-5-or-when-milli-and-micro-meet/</guid><description>&lt;p>This is part five in a series exploring the topic of compute workload abstraction, in earlier posts we discovered how containers fit into the IT ecosystem. In this final part we take a bit of a tangent and look at performance and how adding the next level of abstraction inherits and obscures performance characteristics.&lt;/p>
&lt;h2 id="ok-who-invited-io-to-the-party">OK, who invited I/O to the party?&lt;/h2>
&lt;p>Sharing of a CPU and Memory resources are low hanging fruit from a virtualization perspective, mostly due to their predictable nature in terms of performance, and to some degree the closed nature of the interface to the operating system leading to further stability. Adding I/O sharing and prioritization has always been a challenge, and can be a bit complicated, so let’s look at it all with the analogy of a restaurant – and bear with me, as you may get hungry during the explanation.&lt;/p></description></item></channel></rss>